{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "## this function performs 'natural' or 'human' sorting\n",
    "## when all files named same except for an integer\n",
    "## sort_nicely() function was borrowed from StackOverflow\n",
    "def sort_nicely( l ):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
    "    l.sort( key=alphanum_key )\n",
    "\n",
    "results_dir = '//dnrsrv01/FDrive/IWMShare/Projects/Cycle_Well/LPMT/Conventional/Results/'\n",
    "batch_dirs = ['Batch1/Processed','Batch2/Processed','Batch3/Processed','Batch4/Processed','Batch5/Processed','Batch6/Processed',\n",
    "             'CompletedOutsideInterest/Processed','FinishedFinalCells/Processed']\n",
    "os.chdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(os.path.join(results_dir,batch_dirs[path]))\n",
    "# ## filter files\n",
    "# rng = range(5,60)\n",
    "# rng_string = [str(num) for num in rng]\n",
    "# files = [file for file in files if any(num in file for num in rng_string)]\n",
    "# sort_nicely(files)\n",
    "# files\n",
    "# pd.read_csv(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script pulls the sum column for all rows of a spreadsheet\n",
    "### As written it will search through all CSV's with integers 5-59 in the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch1/8\n",
      "Batch2/8\n",
      "Batch3/8\n",
      "Batch4/8\n",
      "Batch5/8\n",
      "Batch6/8\n",
      "Batch7/8\n",
      "Batch8/8\n"
     ]
    }
   ],
   "source": [
    "##Creates new spreadsheets to be appended together that display the SDF\n",
    "##values for each r_c\n",
    "##Must be checked for duplicates.\n",
    "batches = ['batch1','batch2','batch3','batch4','batch5','batch6','batch7','batch8']\n",
    "for path in range(0,len(batch_dirs)):\n",
    "    current = os.path.join(results_dir,batch_dirs[path])\n",
    "    os.chdir(current)\n",
    "    files = os.listdir(current)\n",
    "    output = batches[path]\n",
    "    ## filter files\n",
    "    rng = range(5,60)\n",
    "    rng_string = [str(num) for num in rng]\n",
    "    files = [file for file in files if any(num in file for num in rng_string)]\n",
    "    sort_nicely(files)\n",
    "    flag = 0\n",
    "    df_out = pd.DataFrame()\n",
    "    ## get last column value for all row cols in files list\n",
    "    for i in range(0,len(files)):\n",
    "        with open(files[i],'r') as f:\n",
    "            df = pd.read_csv(f,index_col=0)\n",
    "            if flag == 0:\n",
    "                df_out['R_C'] = df.index\n",
    "                df_out.set_index('R_C',inplace=True)\n",
    "                flag = 1\n",
    "            df_out[str(i+5)] = df['599']\n",
    "    \n",
    "    df_final = pd.DataFrame()\n",
    "    df_final['R_C'] = df_out.index\n",
    "    df_final.set_index('R_C',inplace=True)\n",
    "    df_final.sort_index(inplace=True)\n",
    "    df_final['SumOfZones'] = df_out.sum(axis=1)\n",
    "    df_final.to_csv('//dnrsrv01/FDrive/IWMShare/Projects/Cycle_Well/LPMT/Conventional/'+output+'sort.csv')\n",
    "    \n",
    "    \n",
    "    print('Batch'+str(path+1)+'/8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of file names\n",
    "uniq = []\n",
    "for i in range(1,60):\n",
    "    a = 'SDFZone'\n",
    "    b = str(i)+'.csv'\n",
    "    c = a+b\n",
    "    uniq.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Zone files from separate batches\n",
    "## could possible check for duplicates here too but \n",
    "## easier to just do in the next Cell.\n",
    "alldfs = []\n",
    "\n",
    "for filename in uniq:\n",
    "    alldfs = []\n",
    "    for path in range(0,len(batch_dirs)):\n",
    "        current = os.path.join(results_dir,batch_dirs[path])\n",
    "        os.chdir(current)\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        alldfs.append(df)\n",
    "\n",
    "    frame = pd.concat(alldfs, axis=0, ignore_index=True)\n",
    "    os.chdir('//dnrsrv01/FDrive/IWMShare/Projects/Cycle_Well/LPMT/Conventional/Results/byZone')\n",
    "    frame.to_csv(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After combining files above, this loop remove duplicates\n",
    "## items to change based on input: dropdup.drop('this_string',axis=1, inplace=True)\n",
    "##                                 dropdup.rename({'this_string':'this_string'},axis='columns',inplace=True) # or remove this line\n",
    "##                                 uniq = ['list','of','filenames']\n",
    "##                                 os.chdir('this/absolute/or/relative/path')\n",
    "## double check file size after - previous issue with file of all zeroes (maybe np.zeroes would fix?)\n",
    "## Last run 3/13/2019 it handled the zeroes folder no problem\n",
    "for filename in uniq:\n",
    "    os.chdir('//dnrsrv01/FDrive/IWMShare/Projects/Cycle_Well/LPMT/Conventional/Results/byZone')\n",
    "    dropdup = pd.read_csv(filename)\n",
    "    dropdup.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    dropdup.rename({'Unnamed: 0.1':'R_C'},axis='columns',inplace=True)\n",
    "    dropdup.drop_duplicates(keep='first',inplace=True)\n",
    "    os.chdir('//dnrsrv01/FDrive/IWMShare/Projects/Cycle_Well/LPMT/Conventional/Results/byZone/removeDuplicates')\n",
    "    dropdup.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
